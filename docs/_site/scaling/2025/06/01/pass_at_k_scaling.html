<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Scaling Laws for Pass@k and Temperature | Kurt Smith</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Scaling Laws for Pass@k and Temperature" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Writeups of my side projects." />
<meta property="og:description" content="Writeups of my side projects." />
<link rel="canonical" href="http://localhost:4000/scaling/2025/06/01/pass_at_k_scaling.html" />
<meta property="og:url" content="http://localhost:4000/scaling/2025/06/01/pass_at_k_scaling.html" />
<meta property="og:site_name" content="Kurt Smith" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-06-01T00:00:00-07:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Scaling Laws for Pass@k and Temperature" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-06-01T00:00:00-07:00","datePublished":"2025-06-01T00:00:00-07:00","description":"Writeups of my side projects.","headline":"Scaling Laws for Pass@k and Temperature","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/scaling/2025/06/01/pass_at_k_scaling.html"},"url":"http://localhost:4000/scaling/2025/06/01/pass_at_k_scaling.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Kurt Smith" />
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Kurt Smith</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Scaling Laws for Pass@k and Temperature</h1>
    <p class="post-meta"><time class="dt-published" datetime="2025-06-01T00:00:00-07:00" itemprop="datePublished">
        Jun 1, 2025
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="markdown-toc">
  <li><a href="#summary" id="markdown-toc-summary">Summary</a></li>
  <li><a href="#motivation" id="markdown-toc-motivation">Motivation</a></li>
  <li><a href="#toy-model" id="markdown-toc-toy-model">Toy Model</a></li>
  <li><a href="#results" id="markdown-toc-results">Results</a>    <ul>
      <li><a href="#temperature-dependence-for-a-single-task" id="markdown-toc-temperature-dependence-for-a-single-task">Temperature dependence for a single task</a></li>
      <li><a href="#how-does-t-scale-with-k-for-an-eval-set" id="markdown-toc-how-does-t-scale-with-k-for-an-eval-set">How does \(T^*\) scale with \(k\) for an eval set?</a>        <ul>
          <li><a href="#gaussian-task-difficulty" id="markdown-toc-gaussian-task-difficulty">Gaussian task difficulty</a></li>
          <li><a href="#exponential-task-difficulty" id="markdown-toc-exponential-task-difficulty">Exponential task difficulty</a></li>
          <li><a href="#power-law-task-difficulty" id="markdown-toc-power-law-task-difficulty">Power-law task difficulty</a></li>
          <li><a href="#comparing-all-three-task-distributions" id="markdown-toc-comparing-all-three-task-distributions">Comparing all three task distributions</a></li>
        </ul>
      </li>
      <li><a href="#deciding-how-large-to-make-k" id="markdown-toc-deciding-how-large-to-make-k">Deciding how large to make k</a></li>
    </ul>
  </li>
  <li><a href="#implications" id="markdown-toc-implications">Implications</a></li>
</ul>

<h1 id="summary">Summary</h1>

<p>\(pass@k\) is widely used for open-ended, verifiable benchmarks (e.g. code, formal proofs), but its nonlinear dependence on both \(k\) and temperature \(T\) makes it difficult to reason about. I use a toy model to study this dependence and find:</p>

<ul>
  <li>The optimal temperature \(T^*\) (that which maximizes \(\mathbb{E}[\text{pass@k}]\)) depends on \(k\). \(T^*(k)\) follows a power law over several decades of \(k\).
    <ul>
      <li>This behavior arises because eval sets contain tasks of varying difficulties (a “difficult task” being one with a low \(pass@1\)). For a single task, \(T^*\) is independent of \(k\).</li>
      <li>As \(k \rightarrow \infty\), \(T^*\) has an asymptotic upper bound that depends only on the single most difficult task in the eval set. For an infinite eval set with no hardest task, the power law scaling would continue indefinitely.</li>
    </ul>
  </li>
  <li>
    <p><strong>The scaling exponent of \(T^*(k)\) is governed by the tail of the task difficulty distribution - not its mean or variance.</strong> Gaussian, exponential, and power-law difficulty distributions yield qualitatively different \(T^*(k)\) behavior, even when matched on the first two moments. Concretely, the \(k\)-exponent increases from 0.73 (Gaussian) to 1.05 (exponential), meaning temperature should scale roughly linearly with \(k\) for exponential difficulty distributions but sub-linearly for Gaussian ones. The plots below show \(T^*(k)\) curves for increasingly fat-tailed eval distributions (Gaussian &lt; exponential &lt; power law).</p>

    <table>
  <tr>
    <td><img src="/assets/images_2025-06-01/image.png" width="300" /></td>
    <td><img src="/assets/images_2025-06-01/image_1.png" width="300" /></td>
  </tr>
  <tr>
    <td><img src="/assets/images_2025-06-01/image_2.png" width="300" /></td>
    <td><img src="/assets/images_2025-06-01/image_3.png" width="300" /></td>
  </tr>
</table>
  </li>
</ul>

<h1 id="motivation">Motivation</h1>

<p>Unlike greedy accuracy (binary per task, insensitive at low solve rates) or perplexity (dependent on a specific reference solution), \(pass@k\) is continuous-valued, increases with \(k\), and can be estimated to arbitrary precision.</p>

<p>However, \(pass@k\) introduces challenges that simpler metrics avoid:</p>

<ol>
  <li><strong><em>Sensitivity to temperature</em></strong>: using \(T=0\) for \(k&gt;1\) is suboptimal since all generations will be identical. It is not clear which \(T\) optimizes \(pass@k\), or whether comparing two models at the same \(T\) is apples-to-apples. (Model A may beat model B at \(T=0.5\) while model B wins at \(T=1\).)</li>
  <li><strong><em>Sensitivity to k</em></strong>: \(pass@k\) is a curve over \(1 \leq k &lt; \infty\). It is not obvious whether a particular set of \(k\) values provides the full picture when comparing two models.</li>
  <li><strong><em>Nonlinear interaction</em></strong>: \(pass@k\) has a nonlinear dependence on \(k\) and \(T\) that cannot easily be factored into independent effects, making it difficult to reason about analytically.</li>
</ol>

<p>I developed a toy model to isolate how \(pass@k\) depends on \(k\), \(T\), and the distribution of task difficulties across an eval set. The key questions:</p>

<ol>
  <li>For a single task, \(pass@k = 1 - (1-pass@1)^k\). But we report the average over a benchmark - how does the \(pass@k\) curve behave for a set of tasks with varying difficulty?</li>
  <li>For a given \(k\), there is an optimal \(T\) that maximizes \(pass@k\) (an exploration vs. exploitation trade-off). How does \(T^*(k)\) scale?</li>
  <li>Does the shape of the task difficulty distribution matter, beyond its mean and variance?</li>
</ol>

<h1 id="toy-model">Toy Model</h1>

<p>For any task prompt, assume there is some non-zero probability (at \(T&gt;0\)) that a given LLM will generate a correct solution. The probability of generating a specific token \(x_i\) scales with \(T\) as:</p>

\[p(x_i) \sim \exp(z_i / T)\]

<p>(where \(T\) also influences the normalization constant). Note the similarity to a zero-mean normal distribution:</p>

\[p(x) \sim \exp(-x^2 / 2 \sigma^2)\]

<p>Consider a discrete normal distribution (i.e. defined only on the integers \(\mathbb{Z}\)). This is equivalent to a softmax function over \(\mathbb{Z}\) where \(z_i = -x_i^2 / 2\) and \(T = \sigma^2\).</p>

<p>Since the possible generations of an LLM form a countable set, we can view this distribution as a simplified representation of an LLM (where each integer represents one generation). A task is represented by an integer \(c\): we sample a random integer \(g\) from the model distribution and say it passes if \(g=c\). Tasks with large \(\lvert c \rvert\) are “difficult” (low probability under the model) and tasks with small \(\lvert c \rvert\) are “easy.”</p>

<p>The model intentionally strips away semantic content to isolate the dependence of \(pass@k\) on temperature, sample count, and the distribution of task difficulties. The absence of task-specific prompts (i.e. we always generate from the same distribution) is not a limitation - what matters is that each task has a \(pass@1\) rate of \(p_{gen}(c \mid T)\) that depends on its difficulty \(\lvert c \rvert\) and the temperature \(T\).</p>

<p>The final element is the evaluation set \(\{c_i\}\). The task difficulties are sampled from a distribution \(p_{task}(c)\) (not to be confused with the generation distribution \(p_{gen}\)). I consider three families:</p>

<table>
  <thead>
    <tr>
      <th>Task distribution</th>
      <th>Form</th>
      <th>Key parameter</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Gaussian</td>
      <td>\(p_{task}(c=j) \sim \exp(-j^2 / 2\sigma_{task}^2)\)</td>
      <td>\(\sigma_{task}\) (task_spread)</td>
    </tr>
    <tr>
      <td>Exponential</td>
      <td>\(p_{task}(c=j) \sim \exp(-\lvert j \rvert / \sqrt{T_{task}})\)</td>
      <td>\(T_{task}\)</td>
    </tr>
    <tr>
      <td>Power law</td>
      <td>\(p_{task}(c=j) \sim \lvert j \rvert^{-\gamma}\)</td>
      <td>\(\gamma\)</td>
    </tr>
  </tbody>
</table>

<p>These families have increasingly fat tails, allowing us to test whether the tail shape - independent of the first two moments - affects the scaling of \(T^*(k)\).</p>

<h1 id="results">Results</h1>

<h2 id="temperature-dependence-for-a-single-task">Temperature dependence for a single task</h2>

<p>Before examining eval sets, it is useful to understand how \(pass@1\) depends on \(T\) for a single task. For \(p_{gen}(c \mid T)\):</p>

<ol>
  <li>At \(T=0\), \(p_{gen}(c)=0\) unless \(c\) is the maximum-likelihood generation.</li>
  <li>As \(T\) increases, probability mass spreads from the mode toward \(c\), increasing \(p_{gen}(c \mid T)\).</li>
  <li>Beyond some optimal \(T\), more mass flows away from \(c\) toward the tails than flows in from the mode, and \(p_{gen}(c \mid T)\) decreases.</li>
  <li>Concretely, for a zero-mean normal distribution, \(p(x)\) is maximized when \(\sigma = \lvert x \rvert\). The plot below illustrates this - compare the values of each curve at \(x=1\):</li>
</ol>

<figure>
<img src="/assets/images_2025-06-01/image_17.png" width="500" />
<figcaption style="font-size: 0.85em; color: #666;">Source: <a href="https://en.wikipedia.org/wiki/Normal_distribution">Wikipedia</a></figcaption>
</figure>

<p>For a single task, this optimal \(T\) is independent of \(k\) (since \(pass@k = 1-(1-pass@1)^k\) is monotonically increasing in \(pass@1\)).</p>

<h2 id="how-does-t-scale-with-k-for-an-eval-set">How does \(T^*\) scale with \(k\) for an eval set?</h2>

<p>For a set of tasks the answer is different. I created eval sets by sampling tasks from each distribution family and calculated \(T^*(k)\) - the temperature maximizing \(pass@k\) for each \(k\) - using Brent’s method.</p>

<p>Key observations:</p>
<ul>
  <li>As \(k \rightarrow \infty\), \(pass@k\) is dominated by the most difficult task (the largest \(\lvert c \rvert\)). Asymptotically, \(T^*\) converges to the value that maximizes \(pass@1\) for that task. This asymptotic value is noisy since it depends on a single extreme task.</li>
  <li>For intermediate values of \(k\), \(T^*\) follows a smooth power law over several decades - this is the scaling regime I focus on.</li>
</ul>

<h3 id="gaussian-task-difficulty">Gaussian task difficulty</h3>

<p>The left plot shows the full \(T^*\) vs \(k\) curve (\(task\_spread\) is the standard deviation of the task distribution). The right plot shows only points with \(0.03 &lt; pass@k &lt; 0.98\), isolating the scaling regime. The bottom plot shows that \(T^*\) also follows a scaling law with respect to \(task\_spread\).</p>

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 10px;">
  <div>
    <img src="/assets/images_2025-06-01/image_4.png" />
  </div>
  <div>
    <img src="/assets/images_2025-06-01/image_5.png" />
  </div>
  <div>
    <img src="/assets/images_2025-06-01/image_6.png" />
  </div>
  <div></div>
</div>

<p>Fitting a regression in this scaling regime (<em>s = task_spread</em>):</p>

\[T^* \approx 0.264 \cdot k^{0.728} \cdot s^{1.283} \text{ ; } R^2=0.9996\]

<h3 id="exponential-task-difficulty">Exponential task difficulty</h3>

<p>The same analysis with tasks drawn from an exponential distribution yields different scaling exponents:</p>

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 10px;">
  <div>
    <img src="/assets/images_2025-06-01/image_7.png" />
  </div>
  <div>
    <img src="/assets/images_2025-06-01/image_8.png" />
  </div>
</div>

\[T^* \approx 0.117 \cdot k^{1.054} \cdot s^{0.957} \text{ ; } R^2= 0.9989\]

<p>The \(k\)-exponent increases from 0.73 to 1.05 - temperature must scale approximately linearly with \(k\) for exponentially-distributed task difficulties, compared to sub-linearly for Gaussian. This points to the central finding: <strong>the optimal temperature for a given eval set does not only depend on the mean and variance of the task difficulty distribution - it depends on the form of the tail.</strong> Two eval sets with identical first and second moments but different tail shapes will require qualitatively different temperature-scaling strategies as \(k\) grows.</p>

<h3 id="power-law-task-difficulty">Power-law task difficulty</h3>

<p>Power-law distributions have even fatter tails, providing a further test of this finding. Here the scaling behavior with respect to \(k\) does not appear at low \(k\) and low \(pass@k\) rates - it only emerges at \(k \approx 20\). (Note: task_stddev_trunc is the equivalent of task_spread here, calculated from the actual truncated distribution since truncation has a much stronger effect on power-law than on Gaussian/exponential distributions.)</p>

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 10px;">
  <div>
    <img src="/assets/images_2025-06-01/image_9.png" />
  </div>
  <div>
    <img src="/assets/images_2025-06-01/image_10.png" />
  </div>
</div>

<h3 id="comparing-all-three-task-distributions">Comparing all three task distributions</h3>

<p>The plots below overlay \(T^*(k)\) for all three distribution families. Gaussian and power-law task sets can have similar \(pass@k\) for \(k&lt;10\), but diverge sharply at larger \(k\). Performance on the Gaussian set saturates by \(k \sim O(100)\), requiring only a modest increase in \(T\) to pass the hardest tasks. For the power-law set, \(T\) must increase by several orders of magnitude to reach the hardest tasks, and even then \(pass@k\) rises slowly with \(k\).</p>

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 10px;">
  <div>
    <img src="/assets/images_2025-06-01/image.png" />
  </div>
  <div>
    <img src="/assets/images_2025-06-01/image_1.png" />
  </div>
  <div>
    <img src="/assets/images_2025-06-01/image_2.png" />
  </div>
  <div>
    <img src="/assets/images_2025-06-01/image_3.png" />
  </div>
</div>

<h2 id="deciding-how-large-to-make-k">Deciding how large to make k</h2>

<p>When planning experiments it is useful to estimate the minimum \(k\) necessary to reach a desired \(pass@k\) score. Comparisons between models are most informative when \(pass@k\) values are near 0.5 rather than clustered near 0 or 1. The plots below show that in many cases there is a linear relationship \(\log(k) \sim \text{logit}(pass@k)\). This suggests that \(pass@k\) for large \(k\) can be extrapolated from a small number of samples, substantially reducing compute requirements.</p>

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 10px;">
  <div>
    <img src="/assets/images_2025-06-01/image_11.png" />
    <p><em>Gaussian task distribution</em></p>
  </div>
  <div>
    <img src="/assets/images_2025-06-01/image_12.png" />
    <p><em>Exponential task distribution</em></p>
  </div>
  <div>
    <img src="/assets/images_2025-06-01/image_13.png" />
    <p><em>Power law task distribution</em></p>
  </div>
  <div></div>
</div>

<h1 id="implications">Implications</h1>

<p>The main practical takeaways from this analysis:</p>

<ul>
  <li><strong>Temperature tuning for pass@k should account for the difficulty distribution of the eval set.</strong> Using a fixed temperature across benchmarks with different tail characteristics will be systematically suboptimal. Fat-tailed benchmarks (where a few tasks are much harder than the rest) require substantially higher temperatures at large \(k\).</li>
  <li><strong>The \(k\)-exponent of \(T^*(k)\) serves as a fingerprint of the eval set’s difficulty distribution.</strong> Measuring this exponent on a real benchmark could reveal whether its difficulty distribution is closer to Gaussian, exponential, or power-law - information that is otherwise hard to extract.</li>
  <li><strong>Extrapolating pass@k via the log-logit relationship</strong> could reduce the number of generations needed to estimate performance at large \(k\), making high-\(k\) evaluation more practical.</li>
  <li><strong>When comparing models on pass@k, the choice of \(k\) and \(T\) is not neutral.</strong> Two models may rank differently depending on these choices, and the degree to which rankings are sensitive to \((k, T)\) depends on the tail of the benchmark’s difficulty distribution.</li>
</ul>

  </div><a class="u-url" href="/scaling/2025/06/01/pass_at_k_scaling.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Writeups of my side projects.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://github.com/kurtosis/kurtosis" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://twitter.com/kurtosis0" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://www.linkedin.com/in/kurtasmith/" target="_blank" title="linkedin">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#linkedin"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

</html>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
